{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gold Stock Price Prediction Project\n",
        "## Complete Machine Learning Pipeline with Multiple Algorithms\n",
        "\n",
        "**Author:** CodeAj Marketplace  \n",
        "**Dataset:** Kaggle Gold Stock Data  \n",
        "**Objective:** Predict gold stock prices using various ML algorithms and compare their performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data manipulation and analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# Visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "\n",
        "# Machine Learning libraries\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Machine Learning Models\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Model persistence\n",
        "import joblib\n",
        "\n",
        "# Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load and Explore the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset - Update path as per your file location\n",
        "# If you have multiple files, combine them\n",
        "\n",
        "# Option 1: Single file\n",
        "df = pd.read_csv('dataset/goldstock v1.csv')\n",
        "\n",
        "# Option 2: Multiple files (uncomment if needed)\n",
        "# df1 = pd.read_csv('dataset/goldstock v1.csv')\n",
        "# df2 = pd.read_csv('goldstock v2.csv')\n",
        "# df2.rename(columns={'Close/Last': 'Close'}, inplace=True)\n",
        "# df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "# Display basic information\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"\\nBasic Statistics:\")\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Preprocessing and Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a copy for processing\n",
        "data = df.copy()\n",
        "\n",
        "# Remove unnamed column if exists\n",
        "if 'Unnamed: 0' in data.columns:\n",
        "    data.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "\n",
        "# Convert Date to datetime\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data = data.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "# Feature Engineering - Create new features\n",
        "data['Day'] = data['Date'].dt.day\n",
        "data['Month'] = data['Date'].dt.month\n",
        "data['Year'] = data['Date'].dt.year\n",
        "data['DayOfWeek'] = data['Date'].dt.dayofweek\n",
        "data['Quarter'] = data['Date'].dt.quarter\n",
        "\n",
        "# Technical Indicators\n",
        "data['Price_Range'] = data['High'] - data['Low']\n",
        "data['Price_Change'] = data['Close'] - data['Open']\n",
        "data['Price_Change_Pct'] = ((data['Close'] - data['Open']) / data['Open']) * 100\n",
        "\n",
        "# Moving averages (if sufficient data)\n",
        "if len(data) >= 5:\n",
        "    data['MA_5'] = data['Close'].rolling(window=5).mean()\n",
        "    data['MA_10'] = data['Close'].rolling(window=10).mean() if len(data) >= 10 else data['Close'].rolling(window=5).mean()\n",
        "\n",
        "# Lag features\n",
        "data['Close_Lag1'] = data['Close'].shift(1)\n",
        "data['Close_Lag2'] = data['Close'].shift(2)\n",
        "data['Volume_Lag1'] = data['Volume'].shift(1)\n",
        "\n",
        "# Drop rows with NaN values created by rolling/lag operations\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "print(\"Data after feature engineering:\")\n",
        "print(data.head())\n",
        "print(\"\\nNew shape:\", data.shape)\n",
        "print(\"\\nFeature columns:\")\n",
        "print(data.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Exploratory Data Analysis (EDA) with Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up the plotting style\n",
        "plt.rcParams['figure.figsize'] = (15, 10)\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# 1. Gold Stock Price Trend\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "\n",
        "# Price Trend\n",
        "axes[0, 0].plot(data['Date'], data['Close'], color='gold', linewidth=2, marker='o')\n",
        "axes[0, 0].set_title('Gold Stock Closing Price Over Time', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Date')\n",
        "axes[0, 0].set_ylabel('Close Price ($)')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Volume Trend\n",
        "axes[0, 1].bar(data['Date'], data['Volume'], color='skyblue', alpha=0.7)\n",
        "axes[0, 1].set_title('Trading Volume Over Time', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Date')\n",
        "axes[0, 1].set_ylabel('Volume')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Price Range (High-Low)\n",
        "axes[1, 0].plot(data['Date'], data['Price_Range'], color='red', linewidth=2, marker='s')\n",
        "axes[1, 0].set_title('Daily Price Range (High - Low)', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Date')\n",
        "axes[1, 0].set_ylabel('Price Range ($)')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Candlestick-like visualization\n",
        "for i in range(len(data)):\n",
        "    color = 'green' if data['Close'].iloc[i] > data['Open'].iloc[i] else 'red'\n",
        "    axes[1, 1].plot([i, i], [data['Low'].iloc[i], data['High'].iloc[i]], color=color, linewidth=1)\n",
        "    axes[1, 1].plot([i, i], [data['Open'].iloc[i], data['Close'].iloc[i]], color=color, linewidth=4)\n",
        "\n",
        "axes[1, 1].set_title('Price Action (Open-Close-High-Low)', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Data Points')\n",
        "axes[1, 1].set_ylabel('Price ($)')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('eda_price_analysis.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"EDA visualizations created successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation Heatmap\n",
        "plt.figure(figsize=(14, 10))\n",
        "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
        "correlation_matrix = data[numeric_cols].corr()\n",
        "\n",
        "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
        "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('Feature Correlation Heatmap', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.savefig('correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTop 10 features correlated with Close price:\")\n",
        "close_corr = correlation_matrix['Close'].sort_values(ascending=False)\n",
        "print(close_corr.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution plots\n",
        "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
        "\n",
        "# Close price distribution\n",
        "axes[0, 0].hist(data['Close'], bins=15, color='gold', edgecolor='black', alpha=0.7)\n",
        "axes[0, 0].set_title('Close Price Distribution', fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Price ($)')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "\n",
        "# Volume distribution\n",
        "axes[0, 1].hist(data['Volume'], bins=15, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "axes[0, 1].set_title('Volume Distribution', fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Volume')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "\n",
        "# Price Change distribution\n",
        "axes[0, 2].hist(data['Price_Change'], bins=15, color='green', edgecolor='black', alpha=0.7)\n",
        "axes[0, 2].set_title('Price Change Distribution', fontweight='bold')\n",
        "axes[0, 2].set_xlabel('Price Change ($)')\n",
        "axes[0, 2].set_ylabel('Frequency')\n",
        "\n",
        "# Box plots\n",
        "axes[1, 0].boxplot([data['Open'], data['High'], data['Low'], data['Close']], \n",
        "                   labels=['Open', 'High', 'Low', 'Close'])\n",
        "axes[1, 0].set_title('Price Statistics Box Plot', fontweight='bold')\n",
        "axes[1, 0].set_ylabel('Price ($)')\n",
        "\n",
        "# Price change percentage\n",
        "axes[1, 1].plot(data['Date'], data['Price_Change_Pct'], color='purple', marker='o')\n",
        "axes[1, 1].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
        "axes[1, 1].set_title('Daily Price Change %', fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Date')\n",
        "axes[1, 1].set_ylabel('Change %')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Moving average comparison\n",
        "if 'MA_5' in data.columns:\n",
        "    axes[1, 2].plot(data['Date'], data['Close'], label='Close', linewidth=2)\n",
        "    axes[1, 2].plot(data['Date'], data['MA_5'], label='MA 5', linewidth=2, linestyle='--')\n",
        "    if 'MA_10' in data.columns:\n",
        "        axes[1, 2].plot(data['Date'], data['MA_10'], label='MA 10', linewidth=2, linestyle='-.')\n",
        "    axes[1, 2].set_title('Moving Averages', fontweight='bold')\n",
        "    axes[1, 2].set_xlabel('Date')\n",
        "    axes[1, 2].set_ylabel('Price ($)')\n",
        "    axes[1, 2].legend()\n",
        "    axes[1, 2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('distribution_analysis.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Prepare Data for Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select features for modeling\n",
        "feature_columns = ['Open', 'High', 'Low', 'Volume', 'Day', 'Month', 'Year', \n",
        "                   'DayOfWeek', 'Quarter', 'Price_Range', 'Price_Change',\n",
        "                   'Price_Change_Pct', 'Close_Lag1', 'Close_Lag2', 'Volume_Lag1']\n",
        "\n",
        "# Add MA features if they exist\n",
        "if 'MA_5' in data.columns:\n",
        "    feature_columns.append('MA_5')\n",
        "if 'MA_10' in data.columns:\n",
        "    feature_columns.append('MA_10')\n",
        "\n",
        "# Prepare X and y\n",
        "X = data[feature_columns]\n",
        "y = data['Close']\n",
        "\n",
        "print(\"Feature matrix shape:\", X.shape)\n",
        "print(\"Target vector shape:\", y.shape)\n",
        "print(\"\\nFeatures used:\")\n",
        "print(feature_columns)\n",
        "\n",
        "# Split the data (80-20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"\\nTraining set size:\", X_train.shape)\n",
        "print(\"Testing set size:\", X_test.shape)\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"\\nData preprocessing completed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train Multiple Machine Learning Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize models dictionary\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(alpha=1.0),\n",
        "    'Lasso Regression': Lasso(alpha=0.1),\n",
        "    'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
        "    'Decision Tree': DecisionTreeRegressor(random_state=42, max_depth=5),\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, max_depth=5),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42, max_depth=3),\n",
        "    'XGBoost': XGBRegressor(n_estimators=100, random_state=42, max_depth=3),\n",
        "    'AdaBoost': AdaBoostRegressor(n_estimators=100, random_state=42),\n",
        "    'Support Vector Regressor': SVR(kernel='rbf', C=100, gamma=0.1),\n",
        "    'K-Nearest Neighbors': KNeighborsRegressor(n_neighbors=3)\n",
        "}\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {\n",
        "    'Model': [],\n",
        "    'Train_R2': [],\n",
        "    'Test_R2': [],\n",
        "    'Train_RMSE': [],\n",
        "    'Test_RMSE': [],\n",
        "    'Train_MAE': [],\n",
        "    'Test_MAE': [],\n",
        "    'CV_Score_Mean': [],\n",
        "    'CV_Score_Std': []\n",
        "}\n",
        "\n",
        "# Dictionary to store trained models\n",
        "trained_models = {}\n",
        "\n",
        "print(\"Training {} models...\\n\".format(len(models)))\n",
        "print(\"=\"*100)\n",
        "\n",
        "# Train each model\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    \n",
        "    # Use scaled data for models that benefit from scaling\n",
        "    if name in ['Support Vector Regressor', 'K-Nearest Neighbors', 'Ridge Regression', \n",
        "                'Lasso Regression', 'ElasticNet', 'Linear Regression']:\n",
        "        X_train_use = X_train_scaled\n",
        "        X_test_use = X_test_scaled\n",
        "    else:\n",
        "        X_train_use = X_train\n",
        "        X_test_use = X_test\n",
        "    \n",
        "    # Train the model\n",
        "    model.fit(X_train_use, y_train)\n",
        "    \n",
        "    # Predictions\n",
        "    y_train_pred = model.predict(X_train_use)\n",
        "    y_test_pred = model.predict(X_test_use)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "    \n",
        "    # Cross-validation (use smaller cv for small datasets)\n",
        "    cv_scores = cross_val_score(model, X_train_use, y_train, cv=min(3, len(X_train)//2), \n",
        "                                scoring='r2')\n",
        "    \n",
        "    # Store results\n",
        "    results['Model'].append(name)\n",
        "    results['Train_R2'].append(train_r2)\n",
        "    results['Test_R2'].append(test_r2)\n",
        "    results['Train_RMSE'].append(train_rmse)\n",
        "    results['Test_RMSE'].append(test_rmse)\n",
        "    results['Train_MAE'].append(train_mae)\n",
        "    results['Test_MAE'].append(test_mae)\n",
        "    results['CV_Score_Mean'].append(cv_scores.mean())\n",
        "    results['CV_Score_Std'].append(cv_scores.std())\n",
        "    \n",
        "    # Store trained model\n",
        "    trained_models[name] = model\n",
        "    \n",
        "    # Print results\n",
        "    print(f\"Train R\u00b2: {train_r2:.4f} | Test R\u00b2: {test_r2:.4f}\")\n",
        "    print(f\"Train RMSE: {train_rmse:.4f} | Test RMSE: {test_rmse:.4f}\")\n",
        "    print(f\"Train MAE: {train_mae:.4f} | Test MAE: {test_mae:.4f}\")\n",
        "    print(f\"CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
        "    print(\"-\"*100)\n",
        "\n",
        "print(\"\\nAll models trained successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Model Performance Comparison and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create results dataframe\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values('Test_R2', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"MODEL PERFORMANCE COMPARISON\")\n",
        "print(\"=\"*100)\n",
        "print(results_df.to_string(index=False))\n",
        "print(\"=\"*100)\n",
        "\n",
        "# Find best model\n",
        "best_model_name = results_df.iloc[0]['Model']\n",
        "best_model = trained_models[best_model_name]\n",
        "\n",
        "print(f\"\\n\ud83c\udfc6 BEST MODEL: {best_model_name}\")\n",
        "print(f\"   Test R\u00b2 Score: {results_df.iloc[0]['Test_R2']:.4f}\")\n",
        "print(f\"   Test RMSE: {results_df.iloc[0]['Test_RMSE']:.4f}\")\n",
        "print(f\"   Test MAE: {results_df.iloc[0]['Test_MAE']:.4f}\")\n",
        "\n",
        "# Save results to CSV\n",
        "results_df.to_csv('model_comparison_results.csv', index=False)\n",
        "print(\"\\nResults saved to 'model_comparison_results.csv'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Comprehensive Model Comparison Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive comparison visualizations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
        "\n",
        "# 1. R\u00b2 Score Comparison\n",
        "x_pos = np.arange(len(results_df))\n",
        "axes[0, 0].barh(x_pos, results_df['Test_R2'], color='skyblue', label='Test R\u00b2')\n",
        "axes[0, 0].barh(x_pos, results_df['Train_R2'], alpha=0.5, color='orange', label='Train R\u00b2')\n",
        "axes[0, 0].set_yticks(x_pos)\n",
        "axes[0, 0].set_yticklabels(results_df['Model'], fontsize=9)\n",
        "axes[0, 0].set_xlabel('R\u00b2 Score', fontweight='bold')\n",
        "axes[0, 0].set_title('Model R\u00b2 Score Comparison', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# 2. RMSE Comparison\n",
        "axes[0, 1].barh(x_pos, results_df['Test_RMSE'], color='lightcoral', label='Test RMSE')\n",
        "axes[0, 1].barh(x_pos, results_df['Train_RMSE'], alpha=0.5, color='lightgreen', label='Train RMSE')\n",
        "axes[0, 1].set_yticks(x_pos)\n",
        "axes[0, 1].set_yticklabels(results_df['Model'], fontsize=9)\n",
        "axes[0, 1].set_xlabel('RMSE (Lower is Better)', fontweight='bold')\n",
        "axes[0, 1].set_title('Model RMSE Comparison', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# 3. MAE Comparison\n",
        "axes[1, 0].barh(x_pos, results_df['Test_MAE'], color='plum', label='Test MAE')\n",
        "axes[1, 0].barh(x_pos, results_df['Train_MAE'], alpha=0.5, color='khaki', label='Train MAE')\n",
        "axes[1, 0].set_yticks(x_pos)\n",
        "axes[1, 0].set_yticklabels(results_df['Model'], fontsize=9)\n",
        "axes[1, 0].set_xlabel('MAE (Lower is Better)', fontweight='bold')\n",
        "axes[1, 0].set_title('Model MAE Comparison', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# 4. Cross-Validation Score with Error Bars\n",
        "axes[1, 1].barh(x_pos, results_df['CV_Score_Mean'], \n",
        "                xerr=results_df['CV_Score_Std'], \n",
        "                color='mediumpurple', \n",
        "                capsize=5,\n",
        "                error_kw={'linewidth': 2, 'ecolor': 'red'})\n",
        "axes[1, 1].set_yticks(x_pos)\n",
        "axes[1, 1].set_yticklabels(results_df['Model'], fontsize=9)\n",
        "axes[1, 1].set_xlabel('Cross-Validation R\u00b2 Score', fontweight='bold')\n",
        "axes[1, 1].set_title('Cross-Validation Performance', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('model_comparison_charts.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Model comparison visualizations created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Additional visualization: Grouped bar chart\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "\n",
        "x = np.arange(len(results_df))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax.bar(x - width/2, results_df['Train_R2'], width, label='Train R\u00b2', \n",
        "               color='#3498db', alpha=0.8)\n",
        "bars2 = ax.bar(x + width/2, results_df['Test_R2'], width, label='Test R\u00b2', \n",
        "               color='#e74c3c', alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('Models', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('R\u00b2 Score', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Train vs Test R\u00b2 Score for All Models', fontsize=16, fontweight='bold', pad=20)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
        "ax.legend(fontsize=10)\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Add value labels on bars\n",
        "for bars in [bars1, bars2]:\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:.3f}',\n",
        "                ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('train_test_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Best Model Detailed Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predictions from best model\n",
        "if best_model_name in ['Support Vector Regressor', 'K-Nearest Neighbors', 'Ridge Regression', \n",
        "                       'Lasso Regression', 'ElasticNet', 'Linear Regression']:\n",
        "    y_train_pred_best = best_model.predict(X_train_scaled)\n",
        "    y_test_pred_best = best_model.predict(X_test_scaled)\n",
        "else:\n",
        "    y_train_pred_best = best_model.predict(X_train)\n",
        "    y_test_pred_best = best_model.predict(X_test)\n",
        "\n",
        "# Create detailed analysis visualizations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 1. Actual vs Predicted (Training)\n",
        "axes[0, 0].scatter(y_train, y_train_pred_best, alpha=0.6, s=100, color='blue', edgecolors='black')\n",
        "axes[0, 0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], \n",
        "                'r--', lw=3, label='Perfect Prediction')\n",
        "axes[0, 0].set_xlabel('Actual Price ($)', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].set_ylabel('Predicted Price ($)', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].set_title(f'{best_model_name} - Training Set\\nR\u00b2 = {r2_score(y_train, y_train_pred_best):.4f}', \n",
        "                     fontsize=14, fontweight='bold')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Actual vs Predicted (Testing)\n",
        "axes[0, 1].scatter(y_test, y_test_pred_best, alpha=0.6, s=100, color='green', edgecolors='black')\n",
        "axes[0, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
        "                'r--', lw=3, label='Perfect Prediction')\n",
        "axes[0, 1].set_xlabel('Actual Price ($)', fontsize=12, fontweight='bold')\n",
        "axes[0, 1].set_ylabel('Predicted Price ($)', fontsize=12, fontweight='bold')\n",
        "axes[0, 1].set_title(f'{best_model_name} - Test Set\\nR\u00b2 = {r2_score(y_test, y_test_pred_best):.4f}', \n",
        "                     fontsize=14, fontweight='bold')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Residuals (Training)\n",
        "train_residuals = y_train - y_train_pred_best\n",
        "axes[1, 0].scatter(y_train_pred_best, train_residuals, alpha=0.6, s=100, color='purple', edgecolors='black')\n",
        "axes[1, 0].axhline(y=0, color='r', linestyle='--', lw=3)\n",
        "axes[1, 0].set_xlabel('Predicted Price ($)', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].set_ylabel('Residuals ($)', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].set_title(f'Residual Plot - Training Set', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Residuals (Testing)\n",
        "test_residuals = y_test - y_test_pred_best\n",
        "axes[1, 1].scatter(y_test_pred_best, test_residuals, alpha=0.6, s=100, color='orange', edgecolors='black')\n",
        "axes[1, 1].axhline(y=0, color='r', linestyle='--', lw=3)\n",
        "axes[1, 1].set_xlabel('Predicted Price ($)', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].set_ylabel('Residuals ($)', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].set_title(f'Residual Plot - Test Set', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('best_model_analysis.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Best model ({best_model_name}) detailed analysis completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Error distribution analysis\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Training error distribution\n",
        "axes[0].hist(train_residuals, bins=15, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "axes[0].axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero Error')\n",
        "axes[0].set_xlabel('Residuals ($)', fontsize=12, fontweight='bold')\n",
        "axes[0].set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
        "axes[0].set_title(f'{best_model_name} - Training Error Distribution', fontsize=14, fontweight='bold')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Testing error distribution\n",
        "axes[1].hist(test_residuals, bins=10, color='lightcoral', edgecolor='black', alpha=0.7)\n",
        "axes[1].axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero Error')\n",
        "axes[1].set_xlabel('Residuals ($)', fontsize=12, fontweight='bold')\n",
        "axes[1].set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
        "axes[1].set_title(f'{best_model_name} - Test Error Distribution', fontsize=14, fontweight='bold')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('error_distribution.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Feature Importance Analysis (for tree-based models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance for tree-based models\n",
        "tree_based_models = ['Decision Tree', 'Random Forest', 'Gradient Boosting', 'XGBoost', 'AdaBoost']\n",
        "\n",
        "if best_model_name in tree_based_models:\n",
        "    # Get feature importance\n",
        "    if hasattr(best_model, 'feature_importances_'):\n",
        "        feature_importance = pd.DataFrame({\n",
        "            'Feature': feature_columns,\n",
        "            'Importance': best_model.feature_importances_\n",
        "        }).sort_values('Importance', ascending=False)\n",
        "        \n",
        "        # Plot feature importance\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.barh(range(len(feature_importance)), feature_importance['Importance'], \n",
        "                 color='teal', alpha=0.8, edgecolor='black')\n",
        "        plt.yticks(range(len(feature_importance)), feature_importance['Feature'])\n",
        "        plt.xlabel('Importance Score', fontsize=12, fontweight='bold')\n",
        "        plt.title(f'Feature Importance - {best_model_name}', fontsize=16, fontweight='bold', pad=20)\n",
        "        plt.grid(True, alpha=0.3, axis='x')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        \n",
        "        print(\"\\nTop 10 Most Important Features:\")\n",
        "        print(feature_importance.head(10).to_string(index=False))\n",
        "else:\n",
        "    print(f\"\\nFeature importance is not available for {best_model_name}\")\n",
        "    print(\"This analysis is only available for tree-based models.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Prediction Timeline Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a comprehensive prediction timeline\n",
        "# Combine train and test indices with their dates\n",
        "train_indices = X_train.index\n",
        "test_indices = X_test.index\n",
        "\n",
        "train_dates = data.loc[train_indices, 'Date']\n",
        "test_dates = data.loc[test_indices, 'Date']\n",
        "\n",
        "# Create visualization\n",
        "plt.figure(figsize=(16, 8))\n",
        "\n",
        "# Plot actual values\n",
        "plt.plot(train_dates, y_train, 'o-', label='Training Actual', \n",
        "         color='blue', linewidth=2, markersize=8, alpha=0.7)\n",
        "plt.plot(test_dates, y_test, 'o-', label='Testing Actual', \n",
        "         color='green', linewidth=2, markersize=8, alpha=0.7)\n",
        "\n",
        "# Plot predictions\n",
        "plt.plot(train_dates, y_train_pred_best, 's--', label='Training Predicted', \n",
        "         color='lightblue', linewidth=2, markersize=6, alpha=0.9)\n",
        "plt.plot(test_dates, y_test_pred_best, 's--', label='Testing Predicted', \n",
        "         color='lightgreen', linewidth=2, markersize=6, alpha=0.9)\n",
        "\n",
        "plt.xlabel('Date', fontsize=12, fontweight='bold')\n",
        "plt.ylabel('Gold Stock Price ($)', fontsize=12, fontweight='bold')\n",
        "plt.title(f'Gold Stock Price Prediction Timeline - {best_model_name}', \n",
        "          fontsize=16, fontweight='bold', pad=20)\n",
        "plt.legend(fontsize=11, loc='best')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.savefig('prediction_timeline.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Prediction timeline visualization created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Model Performance Summary Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a detailed performance summary\n",
        "print(\"\\n\" + \"=\"*120)\n",
        "print(\"COMPREHENSIVE MODEL PERFORMANCE SUMMARY\")\n",
        "print(\"=\"*120)\n",
        "\n",
        "summary_data = []\n",
        "for idx, row in results_df.iterrows():\n",
        "    model_name = row['Model']\n",
        "    summary_data.append({\n",
        "        'Rank': idx + 1,\n",
        "        'Model': model_name,\n",
        "        'Test R\u00b2': f\"{row['Test_R2']:.4f}\",\n",
        "        'Test RMSE': f\"{row['Test_RMSE']:.2f}\",\n",
        "        'Test MAE': f\"{row['Test_MAE']:.2f}\",\n",
        "        'Train R\u00b2': f\"{row['Train_R2']:.4f}\",\n",
        "        'Overfitting': 'Yes' if row['Train_R2'] - row['Test_R2'] > 0.1 else 'No',\n",
        "        'CV Mean': f\"{row['CV_Score_Mean']:.4f}\",\n",
        "        'CV Std': f\"{row['CV_Score_Std']:.4f}\"\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "print(summary_df.to_string(index=False))\n",
        "print(\"=\"*120)\n",
        "\n",
        "# Additional statistics\n",
        "print(\"\\n\ud83d\udcca KEY INSIGHTS:\")\n",
        "print(f\"   \u2022 Best Model: {best_model_name}\")\n",
        "print(f\"   \u2022 Highest Test R\u00b2: {results_df['Test_R2'].max():.4f}\")\n",
        "print(f\"   \u2022 Lowest Test RMSE: ${results_df['Test_RMSE'].min():.2f}\")\n",
        "print(f\"   \u2022 Lowest Test MAE: ${results_df['Test_MAE'].min():.2f}\")\n",
        "print(f\"   \u2022 Average Test R\u00b2 across all models: {results_df['Test_R2'].mean():.4f}\")\n",
        "print(f\"   \u2022 Models with R\u00b2 > 0.8: {len(results_df[results_df['Test_R2'] > 0.8])}\")\n",
        "\n",
        "# Save summary\n",
        "summary_df.to_csv('model_performance_summary.csv', index=False)\n",
        "print(\"\\n\u2705 Summary saved to 'model_performance_summary.csv'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Save the Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the best model and scaler\n",
        "model_filename = f'best_model_{best_model_name.replace(\" \", \"_\").lower()}.pkl'\n",
        "scaler_filename = 'feature_scaler.pkl'\n",
        "\n",
        "joblib.dump(best_model, model_filename)\n",
        "joblib.dump(scaler, scaler_filename)\n",
        "\n",
        "print(f\"\\n\u2705 Best model saved as: {model_filename}\")\n",
        "print(f\"\u2705 Feature scaler saved as: {scaler_filename}\")\n",
        "\n",
        "# Save feature names for future use\n",
        "with open('feature_names.txt', 'w') as f:\n",
        "    for feature in feature_columns:\n",
        "        f.write(f\"{feature}\\n\")\n",
        "\n",
        "print(\"\u2705 Feature names saved as: feature_names.txt\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"MODEL TRAINING AND EVALUATION COMPLETE!\")\n",
        "print(\"=\"*100)\n",
        "print(\"\\n\ud83d\udcc1 Generated Files:\")\n",
        "print(f\"   1. {model_filename} - Best trained model\")\n",
        "print(f\"   2. {scaler_filename} - Feature scaler\")\n",
        "print(\"   3. feature_names.txt - List of features used\")\n",
        "print(\"   4. model_comparison_results.csv - Detailed results\")\n",
        "print(\"   5. model_performance_summary.csv - Performance summary\")\n",
        "print(\"   6. Multiple PNG visualization files\")\n",
        "print(\"\\n\ud83c\udfaf Next Steps:\")\n",
        "print(\"   \u2022 Use the saved model for predictions on new data\")\n",
        "print(\"   \u2022 Deploy the model in a Flask/Django web application\")\n",
        "print(\"   \u2022 Create an API endpoint for real-time predictions\")\n",
        "print(\"=\"*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Model Usage Example - Making Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: How to use the saved model for predictions\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"EXAMPLE: MAKING PREDICTIONS WITH THE SAVED MODEL\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "# Load the saved model and scaler\n",
        "loaded_model = joblib.load(model_filename)\n",
        "loaded_scaler = joblib.load(scaler_filename)\n",
        "\n",
        "# Example: Create a sample input\n",
        "sample_input = X_test.iloc[0:1].copy()  # Take first test sample\n",
        "actual_price = y_test.iloc[0]\n",
        "\n",
        "print(\"\\nSample Input Features:\")\n",
        "print(sample_input.T)\n",
        "\n",
        "# Scale the input if needed\n",
        "if best_model_name in ['Support Vector Regressor', 'K-Nearest Neighbors', 'Ridge Regression', \n",
        "                       'Lasso Regression', 'ElasticNet', 'Linear Regression']:\n",
        "    sample_scaled = loaded_scaler.transform(sample_input)\n",
        "    prediction = loaded_model.predict(sample_scaled)[0]\n",
        "else:\n",
        "    prediction = loaded_model.predict(sample_input)[0]\n",
        "\n",
        "print(f\"\\n\ud83c\udfaf Prediction Results:\")\n",
        "print(f\"   Actual Price: ${actual_price:.2f}\")\n",
        "print(f\"   Predicted Price: ${prediction:.2f}\")\n",
        "print(f\"   Difference: ${abs(actual_price - prediction):.2f}\")\n",
        "print(f\"   Error Percentage: {abs((actual_price - prediction) / actual_price * 100):.2f}%\")\n",
        "print(\"=\"*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. Final Summary and Recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"#\"*120)\n",
        "print(\"#\" + \" \"*118 + \"#\")\n",
        "print(\"#\" + \" \"*38 + \"GOLD STOCK PRICE PREDICTION PROJECT SUMMARY\" + \" \"*37 + \"#\")\n",
        "print(\"#\" + \" \"*118 + \"#\")\n",
        "print(\"#\"*120)\n",
        "\n",
        "print(\"\\n\ud83c\udfaf PROJECT OBJECTIVES ACHIEVED:\")\n",
        "print(\"   \u2713 Loaded and preprocessed gold stock data from Kaggle\")\n",
        "print(\"   \u2713 Performed comprehensive exploratory data analysis\")\n",
        "print(\"   \u2713 Created advanced features using feature engineering\")\n",
        "print(f\"   \u2713 Trained and compared {len(models)} different ML algorithms\")\n",
        "print(\"   \u2713 Generated comprehensive visualizations\")\n",
        "print(\"   \u2713 Identified best performing model\")\n",
        "print(\"   \u2713 Saved model for production use\")\n",
        "\n",
        "print(\"\\n\ud83d\udcc8 MODELS EVALUATED:\")\n",
        "for i, model_name in enumerate(models.keys(), 1):\n",
        "    print(f\"   {i}. {model_name}\")\n",
        "\n",
        "print(f\"\\n\ud83c\udfc6 BEST MODEL: {best_model_name}\")\n",
        "print(f\"   \u2022 Test R\u00b2 Score: {results_df.iloc[0]['Test_R2']:.4f}\")\n",
        "print(f\"   \u2022 Test RMSE: ${results_df.iloc[0]['Test_RMSE']:.2f}\")\n",
        "print(f\"   \u2022 Test MAE: ${results_df.iloc[0]['Test_MAE']:.2f}\")\n",
        "print(f\"   \u2022 Cross-Validation Score: {results_df.iloc[0]['CV_Score_Mean']:.4f} (+/- {results_df.iloc[0]['CV_Score_Std']:.4f})\")\n",
        "\n",
        "print(\"\\n\ud83d\udcca VISUALIZATIONS CREATED:\")\n",
        "viz_files = [\n",
        "    'eda_price_analysis.png',\n",
        "    'correlation_heatmap.png',\n",
        "    'distribution_analysis.png',\n",
        "    'model_comparison_charts.png',\n",
        "    'train_test_comparison.png',\n",
        "    'best_model_analysis.png',\n",
        "    'error_distribution.png',\n",
        "    'prediction_timeline.png'\n",
        "]\n",
        "if best_model_name in tree_based_models:\n",
        "    viz_files.append('feature_importance.png')\n",
        "\n",
        "for i, viz in enumerate(viz_files, 1):\n",
        "    print(f\"   {i}. {viz}\")\n",
        "\n",
        "print(\"\\n\ud83d\udca1 RECOMMENDATIONS FOR DEPLOYMENT:\")\n",
        "print(\"   1. Integrate model into Flask/Django web application\")\n",
        "print(\"   2. Create REST API endpoints for predictions\")\n",
        "print(\"   3. Implement real-time data fetching from stock APIs\")\n",
        "print(\"   4. Add model monitoring and retraining pipeline\")\n",
        "print(\"   5. Deploy on cloud platform (AWS/Azure/GCP)\")\n",
        "print(\"   6. Implement user authentication and dashboard\")\n",
        "print(\"   7. Add prediction confidence intervals\")\n",
        "print(\"   8. Create mobile-responsive UI with Bootstrap 5\")\n",
        "\n",
        "print(\"\\n\ud83d\ude80 FUTURE ENHANCEMENTS:\")\n",
        "print(\"   \u2022 Collect more historical data for better accuracy\")\n",
        "print(\"   \u2022 Implement LSTM/GRU for time series modeling\")\n",
        "print(\"   \u2022 Add sentiment analysis from news articles\")\n",
        "print(\"   \u2022 Include economic indicators as features\")\n",
        "print(\"   \u2022 Implement ensemble methods combining top models\")\n",
        "print(\"   \u2022 Add automated hyperparameter tuning\")\n",
        "print(\"   \u2022 Create prediction intervals and uncertainty estimates\")\n",
        "\n",
        "print(\"\\n\" + \"#\"*120)\n",
        "print(\"#\" + \" \"*40 + \"Thank you for using CodeAj Marketplace!\" + \" \"*39 + \"#\")\n",
        "print(\"#\" + \" \"*118 + \"#\")\n",
        "print(\"#\"*120)\n",
        "print(\"\\n\u2705 Notebook execution completed successfully!\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}